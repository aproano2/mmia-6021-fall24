{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f19747c7-e8de-41d2-9b7c-e61f9cc64f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bdf56f9-5b88-4a00-8327-3f7a4bec3183",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "434ffc33-1973-479c-bc9e-2638e7dfaabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f0a794-4699-44c5-bf4c-00e2b80dc36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d96118f-f5c8-4061-ab13-61f84ccb6177",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0077bbda-b7e2-46b9-a93c-f17fe85efe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3273ab36-464b-40cd-b94f-fd4085eddd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50efa0e9-4e6d-4a05-a59a-a2bbbef2c6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9b47802-aa08-4188-93cf-d4b14c0c1a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d50ab216-0589-4f6e-9a28-7e296ef5b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "def filterPair(p):\n",
    "    try:\n",
    "        return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "            len(p[1].split(' ')) < MAX_LENGTH #and \\\n",
    "#            p[0].startswith(eng_prefixes)\n",
    "    except:\n",
    "        print(p)\n",
    "        \n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b7e2d0e-6cbd-4cd1-bc2e-d33b11be7fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6aa2545-d18d-494a-a696-d553bab728b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2, file):\n",
    "    text = open(file, encoding='utf-8').read().split('\\n')\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')][:2] for l in text ]\n",
    "    pairs = [pair for pair in pairs if len(pair) == 2]\n",
    "\n",
    "    input_lang = Lang(lang1)\n",
    "    output_lang = Lang(lang2)\n",
    "    \n",
    "    pairs = filterPairs(pairs)\n",
    "    \n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee09220c-5d9a-46c2-89f8-064b0fc28f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./models/\"\n",
    "encoder = torch.load(path+\"translate_sp_en_encoder.pt\")\n",
    "decoder = torch.load(path+\"translate_sp_en_decoder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afaf3c7e-3ea0-4b96-8ef0-1cf98d8b39a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted words:\n",
      "eng 12105\n",
      "spa 23411\n"
     ]
    }
   ],
   "source": [
    "file = 'data/spa.txt'\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'spa', file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbbf8658-2080-4242-b6cf-e92aeb2b5239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> that wasn t my fault\n",
      "= eso no fue mi culpa\n",
      "< no fue mi culpa mia <EOS>\n",
      "\n",
      "> please smile\n",
      "= sonreid\n",
      "< favor le puso gasolina en las armas <EOS>\n",
      "\n",
      "> she s at a meeting\n",
      "= ella esta en una reunion\n",
      "< ella es un aliado en la reunion <EOS>\n",
      "\n",
      "> you learn something new every day\n",
      "= cada dia aprendes algo nuevo\n",
      "< aprendiste un nuevo dia de ingles <EOS>\n",
      "\n",
      "> this machine can print sixty pages a minute\n",
      "= este aparato puede imprimir sesenta paginas por minuto\n",
      "< este aparato puede imprimir sesenta paginas por minuto <EOS>\n",
      "\n",
      "> is this price acceptable ?\n",
      "= es aceptable el precio ?\n",
      "< es aceptable el precio de la mia ? <EOS>\n",
      "\n",
      "> why are you wearing my coat ?\n",
      "= por que estas usando mi abrigo ?\n",
      "< por que lleva usted mi abrigo ? <EOS>\n",
      "\n",
      "> tom was just as scared as mary was\n",
      "= tom estaba tan asustado como lo estaba mary\n",
      "< tom estaba tan asustado como lo estaba mary <EOS>\n",
      "\n",
      "> this was his one and only hope\n",
      "= esta era su unica esperanza\n",
      "< era su unica parque solo tiene una necesidad urgente <EOS>\n",
      "\n",
      "> did you already do your homework ?\n",
      "= ya hiciste tu tarea ?\n",
      "< ya hiciste tu tarea ? <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfa9cfcc-c904-4110-99db-72574959988c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ella', 'es', 'mi', 'hermana', 'mayor', '<EOS>'], None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder, decoder, 'she is my sister', input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ce722b4-3454-4eac-a897-f30a68c0ee28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['estoy', 'contento', 'de', 'mi', 'casa', 'es', 'verde', '<EOS>'], None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder, decoder, 'i am cleaning my house', input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3784c171-72dd-437d-8ade-1059865f3ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['cuando', 'puedo', 'hacer', 'los', 'documentos', '?', '<EOS>'], None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder, decoder, 'when is homework due ?', input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "905d6f11-3ee3-4028-baa3-fdee8e0a1a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['tengo', 'miedo', 'de', 'tener', 'miedo', '<EOS>'], None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder, decoder, 'i m scared', input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21926b7d-4180-4fbb-9700-9247b5072473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['como', 'se', 'llama', 'mi', '?', '<EOS>'], None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder, decoder, 'what is my name ?', input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06563b6f-514b-4157-bba6-5f5e45f2a236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['cual', 'es', 'tu', 'nombre', '?', '<EOS>'], None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder, decoder, 'what is your name ?', input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "082f0e28-766f-4f88-abef-aee32a4d61a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['como', 'se', 'llama', 'tu', 'nombre', '?', '<EOS>'], None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder, decoder, 'what is her name ?', input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbd99f77-e71b-4caa-b0a0-bdbf17ab9c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['como', 'se', 'llama', 'tu', 'nombre', '?', '<EOS>'], None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder, decoder, 'what is his name ?', input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6850cf63-2018-4ca1-893c-9469ca7bae79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['muchos', 'anos', 'mas', 'lejos', 'mucho', '<EOS>'], None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder, decoder, 'many years later', input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8544a22d-dc60-4d25-97d2-9b49f9f0e873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['estoy', 'bebiendo', 'un', 'vaso', 'de', 'ingles', '<EOS>'], None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder, decoder, 'i m taking an english class', input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a51f277b-1239-4b56-af14-e1c80ac07da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['estoy', 'estudiando', 'ingles', 'en', 'el', 'estudio', '<EOS>'], None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder, decoder, 'i m studying in an english class', input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b55c790-04d8-47c4-b53e-039cfa998e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['juegan', 'al', 'futbol', 'al', 'futbol', '<EOS>'], None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder, decoder, 'they play soccer', input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c52a1d-4510-4193-99af-b58a8f4cb6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "play v. -> jugar\n",
    "play n. -> actividad de entretenimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d55d7a5a-d4c5-4bd8-b91c-25b50283899a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['mi', 'hermano', 'nunca', 'se', 'fue', 'en', 'mi', 'fiesta', '<EOS>'], None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder, decoder, 'my brother never showed up in my party', input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ee5cd84-9b51-4dff-b417-735f5b892b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./models/\"\n",
    "encoder_attn = torch.load(path+\"translate_sp_en_attn_encoder.pt\")\n",
    "decoder_attn = torch.load(path+\"translate_sp_en_attn_decoder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d944ebc-f69d-4b35-9b1e-7862e2e7aa26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ella', 'es', 'mi', 'hermana', 'llamado', '<EOS>']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder_attn, decoder_attn, 'she is my sister', input_lang, output_lang)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119c4f16-ec11-4dca-b73f-358421ef40e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
